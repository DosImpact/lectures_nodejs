

- [아파치 카프카 for beginners](#아파치-카프카-for-beginners)
- [sec-1 아파치 카프카 기초](#sec-1-아파치-카프카-기초)
  - [카프가 해결하려는 문제](#카프가-해결하려는-문제)
  - [카프카 - 토픽](#카프카---토픽)
    - [컨슈머가 다수인 경우의 작동](#컨슈머가-다수인-경우의-작동)
    - [파티션이 다수인 경우의 작동](#파티션이-다수인-경우의-작동)
  - [Broker, Replication, ISR(In-Sync-Replication)](#broker-replication-isrin-sync-replication)
    - [Broker](#broker)
    - [Replication](#replication)
    - [ISR(In Sync Replica)](#isrin-sync-replica)
  - [파티셔너(Partitioner)란?](#파티셔너partitioner란)
  - [컨슈머 랙(Consumer Lag)이란?](#컨슈머-랙consumer-lag이란)
  - [컨슈머 랙 모니터링 애플리케이션, 카프카 버로우(Burrow)](#컨슈머-랙-모니터링-애플리케이션-카프카-버로우burrow)
    - [Burrow의 특징](#burrow의-특징)
  - [카프카, 레빗엠큐, 레디스 큐의 차이점](#카프카-레빗엠큐-레디스-큐의-차이점)
- [sec-2 아파치 카프카 개발.](#sec-2-아파치-카프카-개발)
  - [AWS에 카프카 클러스터 설치, 실행하기](#aws에-카프카-클러스터-설치-실행하기)


# 아파치 카프카 for beginners


ref : https://www.inflearn.com/course/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%9E%85%EB%AC%B8/lecture/67221?tab=curriculum

--- 

# sec-1 아파치 카프카 기초


## 카프가 해결하려는 문제  


다수의 Apps and Services 와 다수의 (RDB, Warehouse, Key-value Store) 가 있다고 생각해보자.    
시간이 지나고 비즈니스 규모가 점점 커지면서 각 서비스간에 커플링이 강하게 된다.     
이는 장애처리가 어렵고 확장의 비용이 점점 커진다.    
( 거미줄 처럼 연결된 여러 백앤드 서버와 DB들을 20개정도 생각해보자. )  


카프카는 Producer-Consumer 사이에서 결합도를 약하게 만들어주는 중계자 역할을 해준다.   
저장소들을 Producer Service 라고 보고, 데이터가 필요한 곳은 Consumer Service 라고 본다.  
데이터의 흐름을 Topic 별로 전달 해 주며 , 고가용성, 낮은 지연 등의 특징을 가진다.  



## 카프카 - 토픽  


카프카의 데이터 전달을 토픽단위로 한다.  
토픽에는 여러 큐가 있다 (각 큐를 파티션으로 보고, 이들의 집합을 토픽으로 볼 수 있다.)       
토픽은 데이터의 목적(클릭 로그, 푸쉬전송, 위치정보로그)을 단위로 구분한다.    


### 컨슈머가 다수인 경우의 작동  

토픽은 여러개의 파티션으로 구성  

- 첫번째 파티션은 #0 번부터 시작한다.  
- 프로듀서 서비스는 데이터를 큐 구조(파티션)에 쌓는다.  
- 컨슈머는 큐 데이터를 순차적으로 소비한다.    
- 이때 소비한 데이터를 사라지지 않는다.   


- 새로운 컨슈머가 붙었을때, 파티션의 데이터를 처음부터 읽게 된다.   
- ( 조건, 새로운 컨슈머는 다른 그룹이고, auto.offset.reset = earliest 이어야 함)    
- 동일 데이터를 다른 컨슈머가 소비하는 특징이 아주 중요   
- eg) topic: 클릭로그  
- 1. 클릭로그 분석&시각화 - 엘라스틱 서치(컨슈머 1)  
- 2. 클릭로그 백업 - 하둡 저장 ( 컨슈머 2) 


### 파티션이 다수인 경우의 작동  

key의 설정 유무에 따라서, 파티션에 할당하는 방식을 달리할 수 있음  
1. key = null,  기본 파티셔너 사용 -> 라운드 로빈으로 할당   
2. key != null, 기본 파티셔너 사용 -> 키의 해시값을 구해 특정 파티션에 할당  


파티션 확장   

  - 목적 : 파티션을 늘려서 다수의 컨슈머에게 데이터 처리를 분산할 수 있다.  
  - 주의 : 파티션을 늘리는건 가능하지만, 줄이는건 불가능 하다.    

파티션의 데이터 삭제는 옵션에 따라 다르다.   
- log.retention.ms : 최대 record 보존 시간   
- log.retention.byte : 최대 record 보존 크기 byte  



## Broker, Replication, ISR(In-Sync-Replication)  

### Broker

카프카 브로커 : 카프카가 설치되어 있는 서버 단위  
- 3개 이상의 다른 (지역) 서버로 구성하는 것을 권장  

### Replication

레플리케이션 : 파티션을 복제해서, 다른 브로커(서버)에 저장 가능    

- 서버 장애시 고가용성 보장  
- 레플리케이션은 브로커의 갯수보다 많을 수 없다.  
- 원본 파티션은 - leader partition, 복제 파티션은 - follower partition. 
- 프로듀서가 데이터를 할당할때, 전달하는 대상은 리더 파티션이다.  


### ISR(In Sync Replica)

리더+팔로워 파티션을 합쳐서 말함     

- 프로듀서 ACK 라는 옵션 ( 고가용성을 위함  ) : 0 | 1 | all. 

  - ack = 0 : 데이터를 리더 파이션에 전달하고, 응답받지 않는다.  
    - ( 속도는 빠르지만, 데이터가 잘 전달되고, 복제되었는지 모른다. )

  - ack = 1 : 데이터를 리더 파이션에 전달하고, 응답받음.  
    - ( 리더 파티션까지 데이터전달이 됨을 확인하고, 복제성공여부는 모름. )  

  - ack = all : ack 1 옵션에 팔로우 파티션까지 데이터를 잘 저장됨을 확인  
    - ( 속도가 현저히 느리지만, 데이터의 유실은 없다. )  

- 브로커 3개 이상시 레플리케이션을 3으로 유지하는 것을 추천  
- 너무 많은 레플리카는 리소스소비가 커진다.  

--- 

## 파티셔너(Partitioner)란?

카프카 프로듀셔의 중요 개념중 하나, 파티션을 효과적으로 사용하기 위함     
프로듀서 앱에서는, 레코드(토픽,메시지 키,메시지 값) 정보를 파티셔너를 통해 브로커로 전달된다.  

파티셔너의 역할  
- 레코드를 토픽의 어떤 파티션에 넣을지 결정   
- 메시지 키,값에 따라서 파티션을 결정할 수 있다.  
- 기본값은 : uniformStickyPartitioner 로 결정  

- 메시지 키가 있는 경우  

  - hash(메시지키) => 파티션 번호 (동일키는 동일파티션에 들어감을 보장)  
  - 키 단위로, 데이터의 순서를 보장한다.(파티션=큐 이므로)  

- 메시지 키가 없는 경우  

  - 기본적으로 라운드 로빈 방식이지만  
  - 프로듀서에서 배치로 모을 수 있는 최대한의 레코드를 모아서 파티션으로 전달  
  - 이때, 라운드 로빈 방식으로 파티션에 돌아가면서 데이터를 넣는다.  

커스텀 파티셔너를 만들 수 있음  

  - 인터페이스 제공,
  - eg) VIP고객을 위해, 빠른 테이터 처리를 할 수 있다.  
  - 10개 파티션중 8개에 VIP 데이터를 넣어, 우선순위큐 효과를 누릴 수 있음.  

--- 

## 컨슈머 랙(Consumer Lag)이란?

lag은 카프카 운영상 중요한 모니터링 지표이다.   


오프셋 : 파티션에 데이터가 순차적으로 들어갈때, 데이터에 오프셋이라는 숫자가 붙게됨  
- 컨슈머가 마지막으로 읽은 offset과, 프로듀서가 마지막으로 넣은 offset 정보을 안다.  
- 컨슈머와 프로듀서의 오프셋 차이가 Consumer lag 이다.  
- lag의 지표는 컨슈머의 상태를 알아볼 수 있다.  

- 파티션이 2개이고, 컨슈머 그룹이 1개라면 lag은 2개가 측정될 수 있다.  
- 이중 높은 숫자의 lag을 records-lag-max 라고 부른다.  

모니터링 지표로 lag.  
- lag은 producer-consumer의 offset 차이이며, 여러개 존재한다.
- lag의 지표로 - 컨슈머의 성능을 개선시킬 판단 가능  

---

## 컨슈머 랙 모니터링 애플리케이션, 카프카 버로우(Burrow)

카프카 버로우(Burrow) : kafka lag 을 모니터링 하기 위한 오픈소스  

kafka-client : java, rust 등으로 kafka-consumer를 구현  

- 이때 kafka-client에서 구현한  kafka-consumer 객체에서 lag정보를 얻기 가능  
- 실시간 데이터 모니터링을 - influxDB, elasticsearch 넣기 - Grafana 대시보드 확인  

컨슈머 단위에서, lag을 모니터링하는것은 운영리소스가 많이 든다.  
- 컨슈머 로직단에서 lag 수집 == 컨슈머 상태에 의존하게 된다.  
- 컨슈머 마다 , 데이터 저장소 및 저장 로직을 구현해야한다.  


링크드인에서 효과적으로 컨슈머 lag을 모니터링하도록 오픈소스 burrow을 출시  
- Golang 으로 작성됨  

### Burrow의 특징  

1. 멀티 카프카 클러스터 지원    

- 카프카를 운영할때, 2개 이상의 카프카 클러스터를 운영  
- (브로커가 모여서 1개의 클러스터가 되는 듯)  
- Burrow 1개로 모두 모니터링 가능  

2. Sliding window을 통한 consumer status 확인   

- consumer status = "ERROR" | "WARNING" | "OK"  
- ERROR : 데이터는 늘고있는데, 컨슈머 작동 안함  
- WARNING : lag이 증가하는 추세  
- OK : 


3. HTTP api 조회 가능  
- 추가 상태계 붙이기 가능 ( fluxDB 등 )


## 카프카, 레빗엠큐, 레디스 큐의 차이점

메시징 플랫폼을 크게 2개로 구분  
1. 메시지 브로커  : 이벤트 브로커 역할 불가능 eg)Redis,RabbitMQ.   
2. 이벤트 브로커  : 메시지 브로커의 역할도 가능 eg)Kafka,AWS 키네시스   


미들웨어 아키텍처 : 어플리케이션 마다 효과적으로 연결  

메시지 브로커 특징  
  - 메시지를 처리하고 나면, 짧은 시간내 삭제된다.  


이벤트 브로커 특징  
  - 레코드(이벤트,혹은 메시지 자료구조) 하나를 관리 및 인덱스로 접근  
  - 특정 시간동안 레코드를 보관  
    - 1.딱 한번 발생한 이벤트를 저장하여 - 단일 진실 공급원  
    - 2.장애 지점부터 재처리가 가능  
    - 3.많은 양의 실시간 스트림데이터 효과적으로 처리  


--- 


# sec-2 아파치 카프카 개발.  


## AWS에 카프카 클러스터 설치, 실행하기

3개 이상의 카프카 브로커 클러스터를 구축해봐야 카프카를 써봤다 라고 한다.  
- 고가용성은 클러스터 단위에서 진가를 발휘    
- EC2 3개를 발급해서 클러스터를 만들고 사용해보자.  
- console producer - consumer 로 연동해보자.   


