
- [Object - Pod](#object---pod)
  - [개념](#개념)
  - [실습 전 알아둬야할 사항](#실습-전-알아둬야할-사항)
  - [실습 - pod 올리기](#실습---pod-올리기)
  - [실습 - ReplicationController](#실습---replicationcontroller)
  - [실습 - label](#실습---label)
  - [실습 - Node Schedule](#실습---node-schedule)
- [Service - ClusterIP, NodePort, LoadBalancer](#service---clusterip-nodeport-loadbalancer)
  - [실습 - Service ClusterIP 파드가 IP변경되어도 Service IP로 접속 가능](#실습---service-clusterip-파드가-ip변경되어도-service-ip로-접속-가능)
  - [실습 - Service NodePort](#실습---service-nodeport)
  - [실습 - Service LoadBalancer](#실습---service-loadbalancer)
- [Volume - emptyDir, hostPath, PV/PVC](#volume---emptydir-hostpath-pvpvc)
  - [실습](#실습)
- [ConfigMap, Secret - Env, Mount](#configmap-secret---env-mount)
  - [실습](#실습-1)
- [Namespace, ResourceQuota, LimitRange](#namespace-resourcequota-limitrange)

# Object - Pod 
https://kubetm.github.io/k8s/03-beginner-basic-resource/pod/

## 개념

컨테이너
- 파드안에는 여러 컨테이너 존재
- 컨테이너 끼리는 포트가 겹치면 안된다.
- 파드에는 고유의 IP주소가 할당되고 이는 인터널에서만 접근 가능하다. 외부에서 접근은 불가능하다.
- pod에 문제가 발생이 생기면 다시 만들어지고, 이때 IP는 다시 할당된다.

라벨
- key-value가 한쌍이다.
- Pod들을 분류하는데 사용된다. 뿐만 아니라 k8s 오브젝트에 모두 라벨을 달 수 있다.
- 예를들어 type:webapp 이며, profile이 dev인 pod만 고를 수 있다.
- 해시 태그를 달아둔것 같은 기능

노드 스케쥴
- 1. Pod를 배포할 노드를 직접 지정하는 방법
- 어떤 노드인지 명시함으로써 가능하다. nodeSelector 라는 필드를 사용
- 2. k8s의 스케쥴러가 판단해서 배포하는 방법
- 필요한 리소스의 양을 적어주면 된다. resources: requests,limit 등의 필드를 사용

## 실습 전 알아둬야할 사항

minikube 대시보드를 접속한다.
minikube 대시보드에서 blueprint yaml을 올릴 수 있다. (pod, service 등등 생성)
minikube 는 docker 컨테이너 이므로, 해당 bash에 들어가는것이 master node에 들어가는 것이다.
minikube 에서 pod의 bash로 접속이 가능하다.


## 실습 - pod 올리기

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
spec:
  containers:
  - name: container1
    image: kubetm/p8000
    ports:
    - containerPort: 8000
  - name: container2
    image: kubetm/p8080
    ports:
    - containerPort: 8080
```

```
minikube bash 접속 > Pod ip 알아내기 > 아래 명령어 수행


# curl 10.244.0.25:8000
containerPort : 8000

# curl 10.244.0.25:8080
containerPort : 8080
---
각 Pod의 컨테이너 접속해서 > 아래 명령어수행

root@pod-1:/# curl 0.0.0.0:8080
containerPort : 8080
root@pod-1:/# curl 0.0.0.0:8000
containerPort : 8000
---
만약 동일 Pod안에서 port가 충돌되면 하나의 파드에서 오류가 난다.
```

## 실습 - ReplicationController

아래 ReplicationController 을 통해서 만든 pod는 지우게 되면 다시 만들어지게 된다.

```yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: replication-1
spec:
  replicas: 1
  selector:
    app: rc
  template:
    metadata:
      name: pod-1
      labels:
        app: rc
    spec:
      containers:
      - name: container
        image: kubetm/init
```

## 실습 - label

아래 6개의 파드를 올린다.
- dev, prod 환경 각각 web-server-db를 올리자.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  labels:
    type: web
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-2
  labels:
    type: db
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init 
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-3
  labels:
    type: server
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init  
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-4
  labels:
    type: web
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-5
  labels:
    type: db
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init 
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-6
  labels:
    type: server
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init  
```

아래 서비스는 web인 pod만 선택하는것을 확인할 수 있다.
```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-1
spec:
  selector:
    type: web
  ports:
  - port: 8080
```

아래 서비스는 prod 환경의 pod만 선택하는것을 확인할 수 있다.
```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-1-prod
spec:
  selector:
    lo: prod
  ports:
  - port: 8080
```

## 실습 - Node Schedule

실습하기 전에 minikube을 통해서 node를 하나 추가하자.

eg) 특정 노드를 명시해서 pod를 띄우는 blueprint
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-3
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube-m02
  containers:
  - name: container
    image: kubetm/init
```

eg) 자원에 따라 스케쥴링 하여 pod를 띄우는 blueprint
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-4
spec:
  containers:
  - name: container
    image: kubetm/init
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 3Gi
```

# Service - ClusterIP, NodePort, LoadBalancer

Pod에도 IP가 있는데 서비스를 만들어 붙이는 이유는 ? 
Pod는 쉽게 죽고 재생성이 되도록 만들어진 객체이다. 그래서 IP가 수시로 변할 수 있다. 
그래서 Service가 항상 연결된 IP를 제공하도록 한다. 

ClusterIP : 클러스터 내에서만 접근이 가능한 IP, External에서 접근할 수 없다.ㅇ
- 여러개의 Pod를 연결해서 트래픽을 분산시켜준다.
- Service의 기본 타입은 ClusterIP 이다.
- 외부에서 접근이 불가능하고, 내부의 인가된 사용자만 사용이 가능하다. 내부 대시보드, Pod상태의 서비스 상태 디버깅 등

NodePort : 모든 노드에 동일한 포트를 오픈시켜서 서비스를 연결시켜준다.
- 이후 ClusterIP와 유사하게 동작한다.
- Pod가 있는 노드에만 nodePort가 열리는것이 아니다.!
- 그래서 목적지 파드가 없는 노드에서도 파드에 도달할 수 있다.
- 옵션 : externalTrafficPolicy:Local  > 서비스가 해당 노드안의 파드들까지만 트래픽을 전달해준다.
- 외부에서 접근 가능하나, 보안적으로 내부망 연결해서 접속하도록 한다.


Load Balancer
- NodePort의 성격을 그대로 가지고 있다.
- 하지만 별도로 플러그인을 설치를 해서, 클러스터 외부에서 로드밸런서를 만들어야 한다.
- 그래고 해당 로드밸런서에 IP 할당해서 클러스터 접근가능하도록 한다.
- 실제적으로 외부의 서비스를 노출 시키도록 하여, 내부의 IP를 노출시키지 않는다.

## 실습 - Service ClusterIP 파드가 IP변경되어도 Service IP로 접속 가능

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-1
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080    


서비스 ClusterIP로 접근하면 파드의 IP에 상관없이 응답이 온다.
>curl 10.111.143.65:9000/hostname
Hostname : pod-1

```

## 실습 - Service NodePort

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-2
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube-m02
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-2
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
    nodePort: 30000
  type: NodePort
  externalTrafficPolicy: Local
---
ClusterIP 처럼 접근이 가능하다.
>curl 10.111.143.65:9000/hostname
Hostname : pod-1
--- 
하지만 NodePort로 해당 노드에 IP로 찔러서 접근이 가능하다.
>curl localhost:30000/hostname
Hostname : pod-1
---
아래처럼 트래픽이 각 노드로 분산이 된다. 
노드1, 노드2에 동시에 30000번 포트가 열린것이고 각각의 노드의 파드로 트래픽을 분산시켜준다.
이는 노드1에서 접근해도 노드2의 Pod로도 트래픽을 보내준다.

>curl localhost:30000/hostname
Hostname : pod-1
>curl localhost:30000/hostname
Hostname : pod-2

```

## 실습 - Service LoadBalancer

```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-3
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
  type: LoadBalancer
---

서비스를 보면 ExternalIP가 아직 Pending 상태로 외부 아이피 할당을 기다리고 있다.

> kubectl get service
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
svc-3            LoadBalancer   10.110.41.44    <pending>     9000:30929/TCP   59s

```
# Volume - emptyDir, hostPath, PV/PVC

emptyDir  

컨테이너들 끼리 데이터를 공유하기 위해 볼륨을 사용한다. 최초에는 비어 있다.   
예) 컨테이너 웹서버의 결과물을 백앤드 컨테이너가 가져가 로컬 파일처럼 사용  
Pod가 재생성이 되면 emptyDir 은 사라진다. 휘발성을 가진 내용만 넣어야 한다.  


hostPath

Pod들이 올라간 Node에서 볼륨을 만들어서 사용하는 것이다.  
Pod들이 죽어도 Node에 볼륨이 남아있는 장점이 있지만, Pod가 다른 노드에 생성될 수 있기때문에 일관성이 없다.  
Node가 추가될때마다 상위 구성의 공유 볼륨을 리눅스에서 넣어 일관성을 유지시킬 수 있긴하다.  
예) 각각의 Node에는 각 시스템 설정파일들이 있고 이를 읽을때 사용한다.
- 사전에 해당 Node에 경로가 있어야 한다. 
- Pod에서 데이터를 쓰는 용도가 아니다.


PV/PVC

PV : PersistantVolume을 / Claim
Pod에 영속성이 있는 볼륨을 제공하기 위함이다. 외부의 NFS, Storage를 연동하기 위한 솔류션이다.  
2개 영역으로 나누었다. User 영역은 Pod서비스를 배포하는 사람, Admin 영역은 K8S자체를 운영하는 관리자 이다.  
Admin : 각 볼륨들을 정의하고, PersistantVolume을 만든다.
- 어떤 서버의 어떤 경로의 스토리지를 사용하고, 권한, 총 Storage크기 등등 설정
User : PersistentVolumeClain 을 통해서 Storage를 Requests해서 사용할 수 있다. 
- Pod에는 1GB가 필요하다 > K8S가 적절한 PersistantVolume을 선택한다.

## 실습

# ConfigMap, Secret - Env, Mount

환경변수를 관리하기 위한것이 ConfigMap, Secret 이다.  
환경변수 중 상수값은 ConfigMap, 비밀키값등은 Secret에 보관한다.  Env를 각 컨테이너에 주입시키도록 한다.  

1. Env Literal , 상수로 환경변수 넣기 


2. Env File , 파일로 환경변수 넣기
key 가 file.txt Value 가 Content 이다.
kubectl 명령어로 configmap과 secret을 등록할 수 있다.
secret 은 base64 인코딩을 해서 넣는다.
한번 주입되면 변경되지 않는다.

3. Volumne mount , 볼륨으로 환경변수 넣기

볼륨이 마운트 되므로, 외부에 의해 환경 변수가 변경된다.

## 실습

# Namespace, ResourceQuota, LimitRange

왜 써야 하는가 ? K8s는 전체 자원이 있다.  메모리와 CPU가 대표적으로 있다.  
cluster안에는 Namespace가 있다. 한 Namespace 안의 Pod가 모든 자원을 써버리면 다른 Namespace에 문제가 발생한다.  

ResourceQuota 로 Namespace별 자원을 할당할 수 있다.
한 Pod의 자원 사용량이 일정 수준 이하여야지 Namespace에 들어올 수 있도록 하는것이 LimitRange 이다.
이런 ResourceQuota, LimitRange는 Namespace뿐 아니라, Cluster단위에도 적용시킬 수 있다.  

1. Namespace

한 Namespace 안에는 중복된 이름으로 object(Pod 등)를 만들 수 없다.
타 Namespace과 자원이 분리된다. Service의 Selector는 동일 Namespace에서만 사용 된다.  
PersistantVolume 처럼 NameSpace와 상관없이 사용되는 자원도 있다.  
- Namespace를 지우게 되면, 그 안의 자원(Pod)도 사라지게 된다.
- 서로 다른 Namespace의 Pod는 연결이 기본적으로 된다. 추후 Network 설정으로 대응

2. ResourceQuota
Namespace의 전체 자원을 명시 해준다.  
ResourceQuota가 지정된 Namespace에 Pod를 만들려면, 리소스 스펙을 지정해줘야 한다.  
제한 대상 : Compute Resource (CPU, Memory, Storage), Object Count (Pod, Service, ConfigMap, PVC..)  
- k8s 버전마다 제한할 수 있는 오브젝트가 다르다.  

3. LimitRange  

각각의 Pod마다 Namespace에 들어올 수 있는지 체크를 해준다.
```
    min: # 메모리 하한값
      memory: 0.1Gi
    max: # 메모리 상한값
      memory: 0.5Gi
    maxLimitRequestRatio: # Pod의 상한/하한 <= 3 이어야 한다. 
      memory: 3
    defaultRequest: # Pod의 자원 할당 디폴트값
      memory: 0.5Gi
    default: # Pod의 자원 할당 디폴트값
      memory: 0.5Gi
```


