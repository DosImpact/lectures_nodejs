
- [Object - Pod](#object---pod)
  - [개념](#개념)
  - [실습 전 알아둬야할 사항](#실습-전-알아둬야할-사항)
  - [실습 - pod 올리기](#실습---pod-올리기)
  - [실습 - ReplicationController](#실습---replicationcontroller)
  - [실습 - label](#실습---label)
  - [실습 - Node Schedule](#실습---node-schedule)
- [Object - Service: ClusterIP, NodePort, LoadBalancer](#object---service-clusterip-nodeport-loadbalancer)
  - [실습 - Service ClusterIP 파드가 IP변경되어도 Service IP로 접속 가능](#실습---service-clusterip-파드가-ip변경되어도-service-ip로-접속-가능)
  - [실습 - Service NodePort](#실습---service-nodeport)
  - [실습 - Service LoadBalancer](#실습---service-loadbalancer)
- [Object - Volume : emptyDir, hostPath, PV/PVC](#object---volume--emptydir-hostpath-pvpvc)
  - [실습](#실습)
- [ConfigMap, Secret - Env, Mount](#configmap-secret---env-mount)
  - [실습](#실습-1)
- [Namespace, ResourceQuota, LimitRange](#namespace-resourcequota-limitrange)
  - [1. Namespace](#1-namespace)
  - [2. ResourceQuota](#2-resourcequota)
  - [3. LimitRange](#3-limitrange)
  - [실습 Namespace](#실습-namespace)
  - [실습 - Namespace에 같은 이름의 pod 생성 불가](#실습---namespace에-같은-이름의-pod-생성-불가)
  - [실습 - 다른 네임스페이스의 pod가 연결되는것을 확인](#실습---다른-네임스페이스의-pod가-연결되는것을-확인)
  - [실습 - 노드포트는 namespace내 중복되면 안된다.](#실습---노드포트는-namespace내-중복되면-안된다)
  - [실습 - host-path의 volumne 마운트는 namespace간 연동된다.](#실습---host-path의-volumne-마운트는-namespace간-연동된다)
  - [실습 ResourceQuota](#실습-resourcequota)
  - [실습 - ResourceQuota 자원을 넘어선 파드 생성 불가](#실습---resourcequota-자원을-넘어선-파드-생성-불가)
  - [실습 - ResourceQuota 파드수 제한](#실습---resourcequota-파드수-제한)
  - [실습 - 파드를 먼저 생성 후 ResourceQuota를 만들 경우](#실습---파드를-먼저-생성-후-resourcequota를-만들-경우)
  - [실습 LimitRange](#실습-limitrange)
  - [실습 LimitRange 설정 후 Pod의 limit 걸리는 경우, ratio 걸리는 경우](#실습-limitrange-설정-후-pod의-limit-걸리는-경우-ratio-걸리는-경우)
  - [실습 LimitRange의 기본설정을 따라가는 Pod 리소스 확인](#실습-limitrange의-기본설정을-따라가는-pod-리소스-확인)
  - [실습 LimitRange를 여러개 설정은 권장하지 않음](#실습-limitrange를-여러개-설정은-권장하지-않음)

# Object - Pod 
https://kubetm.github.io/k8s/03-beginner-basic-resource/pod/

## 개념

컨테이너
- 파드안에는 여러 컨테이너 존재
- 컨테이너 끼리는 포트가 겹치면 안된다.
- 파드에는 고유의 IP주소가 할당되고 이는 인터널에서만 접근 가능하다. 외부에서 접근은 불가능하다.
- pod에 문제가 발생이 생기면 다시 만들어지고, 이때 IP는 다시 할당된다.

라벨
- key-value가 한쌍이다.
- Pod들을 분류하는데 사용된다. 뿐만 아니라 k8s 오브젝트에 모두 라벨을 달 수 있다.
- 예를들어 type:webapp 이며, profile이 dev인 pod만 고를 수 있다.
- 해시 태그를 달아둔것 같은 기능

```
Pod1 : type:web, profile:dev
Pod2 : type:db, profile:dev
Pod3 : type:server, profile:dev

Pod4 : type:web, profile:prod
Pod5 : type:db, profile:prod
Pod6 : type:server, profile:prod
```

노드 스케쥴
- 1. Pod를 배포할 노드를 직접 지정하는 방법
- 어떤 노드인지 명시함으로써 가능하다. nodeSelector 라는 필드를 사용
- 2. k8s의 스케쥴러가 판단해서 배포하는 방법
- 필요한 리소스의 양을 적어주면 된다. resources: requests,limit 등의 필드를 사용

## 실습 전 알아둬야할 사항

minikube 대시보드를 접속한다.
minikube 대시보드에서 blueprint yaml을 올릴 수 있다. (pod, service 등등 생성)
minikube 는 docker 컨테이너 이므로, 해당 bash에 들어가는것이 master node에 들어가는 것이다.
minikube 에서 pod의 bash로 접속이 가능하다.


## 실습 - pod 올리기

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
spec:
  containers:
  - name: container1
    image: kubetm/p8000
    ports:
    - containerPort: 8000
  - name: container2
    image: kubetm/p8080
    ports:
    - containerPort: 8080
```

```
1. 
각각 8080, 8000번 포트로 접근가능한 컨테이너 2개를, 1개의 파드로 올렸다.

2. docker 데스크탑 > minikube 노드 중 아무거나 bash 접속 > k8s대시보드에서 Pod ip 확인 > 아래 명령어 수행

# curl 10.244.0.25:8000
containerPort : 8000

# curl 10.244.0.25:8080
containerPort : 8080


3. k8s대시보드에서 > 각 Pod의 컨테이너 shell in > 아래 명령어수행

root@pod-1:/# curl 0.0.0.0:8080
containerPort : 8080
root@pod-1:/# curl 0.0.0.0:8000
containerPort : 8000
---

*만약 동일 Pod안에서 port가 충돌되면 하나의 파드에서 오류가 난다.
- 파드의 로그 > 애러를 확인하자.


```

## 실습 - ReplicationController



```yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: replication-1
spec:
  replicas: 1
  selector:
    app: rc
  template:
    metadata:
      name: pod-1
      labels:
        app: rc
    spec:
      containers:
      - name: container
        image: kubetm/init
```

```
1. ReplicationController 을 통해서 pod 만들 수 있다.

2. Pod를 삭제해도, ymal 정의에 따라 다시 Pod를 만든다.

3. 이때 파드의 IP는 재할당된다.

4. ReplicationController를 삭제하면, 관련 Pod가 종료되고, 이후 ReplicationController 도 삭제된다.

```

## 실습 - label

아래 6개의 파드를 올린다.
- 즉, dev, prod 환경에 대해서 각각 web-server-db 3티어 Pod를 만든다..

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  labels:
    type: web
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-2
  labels:
    type: db
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init 
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-3
  labels:
    type: server
    lo: dev
spec:
  containers:
  - name: container
    image: kubetm/init  
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-4
  labels:
    type: web
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-5
  labels:
    type: db
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init 
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-6
  labels:
    type: server
    lo: prod
spec:
  containers:
  - name: container
    image: kubetm/init  
```

아래 서비스는 web인 pod만 선택하는것을 확인할 수 있다.
```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-1
spec:
  selector:
    type: web
  ports:
  - port: 8080
```


아래 서비스는 prod 환경의 pod만 선택하는것을 확인할 수 있다.
```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-1-prod
spec:
  selector:
    lo: prod
  ports:
  - port: 8080
```

```
1. Service:spec:selector를 이용해서 목적에 맞는 Pod를 선택할 수 있다. 
2. 대시보드의 서비스로 들어가보면, 선택된 파드 목록이 나온다. 

```

## 실습 - Node Schedule

실습하기 전에 minikube을 통해서 node를 하나 추가하자.

eg) 특정 노드를 명시해서 pod를 띄우는 blueprint
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-m02-1
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube-m02
  containers:
  - name: container
    image: kubetm/init
```

eg) 자원에 따라 스케쥴링 하여 pod를 띄우는 blueprint
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-m0x-2
spec:
  containers:
  - name: container
    image: kubetm/init
    resources:
      requests:
        memory: 2Gi
      limits:
        memory: 3Gi
```
```
1. 대시보드 > 노드 > 상세보기에서 노드의 리소스를 확인 가능
2. 위 두 예제는 특정 노드에 배포, 자원 양에 따른 배포를 보여준다.
3. 파드가 배포 된 후 requests만큼의 자원이 메모리 요청(bytes) 부분에 보인다. 

```

# Object - Service: ClusterIP, NodePort, LoadBalancer

Pod에도 IP가 있는데 서비스를 만들어 붙이는 이유는 ?   
- Pod는 쉽게 죽고 재생성이 되도록 만들어진 객체이다. 그래서 IP가 수시로 변할 수 있다. 
- 그래서 Service가 Pod의 연결을 제공 한다. 

ClusterIP : 클러스터 내에서만 접근이 가능한 IP, External에서 접근할 수 없다.  
- 여러개의 Pod를 연결해서 트래픽을 분산시켜준다. ( selector로 pod 선택 )
- Service의 기본 타입은 ClusterIP 이다.
- ( service_IP:port > (pod-ip):tagetPort )
- 목적 : 외부에서 접근이 불가능하고, 내부의 인가된 사용자만 사용이 가능하다. 내부 대시보드, Pod상태의 서비스 상태 디버깅 등

NodePort : 모든 노드에 동일한 포트를 오픈시켜서 서비스를 연결시켜준다.
- 이후 ClusterIP와 유사하게 동작한다. 
- ( Node_IP:NodePort > service_IP:port > (pod-ip):targetPort )
- Pod가 있는 노드에만 nodePort가 열리는것이 아니다.! 
- 파드가 없는 노드에서도 타 노드로 트래픽을 전달하여 목적지 파드에 도달할 수 있다.
- *옵션 : externalTrafficPolicy:Local  > 서비스가 해당 노드안의 파드들까지만 트래픽을 전달해준다.
- 목적 : 외부에서 접근 가능하나, 보안적으로 내부망 연결해서 접속하도록 한다.


Load Balancer
- NodePort의 성격을 그대로 가지고 있다.
- ( LoadBalancer -> Node1_IP:NodePort, Node2_IP:NodePort -> service_IP:port > (pod-ip):targetPort )
- 하지만 별도로 플러그인을 설치를 해서, 클러스터 외부에 로드밸런서를 만들어야 한다.
- 해당 로드밸런서에 IP 할당해서 클러스터 접근가능하도록 한다.
- 목적 : 실제적으로 외부의 서비스를 노출 시키도록 하여, 내부의 IP를 노출시키지 않는다.

## 실습 - Service ClusterIP 파드가 IP변경되어도 Service IP로 접속 가능

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-s-1
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-1
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
```

```
1. 서비스 리소스 정보에, 클러스터 IP가 할당되었다.

2. (ServiceIP):(port) 로 파드에 요청 보낼 수 있다.
>curl 10.111.143.65:9000/hostname
Hostname : pod-1

- 서비스 ClusterIP로 접근하면 유동적인 파드의 IP에 상관없이 응답이 온다.

3. 서비스에 파드가 여러개 붙으면, 로드밸런싱이 된다.
```

## 실습 - Service NodePort

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-n-1
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-n-2
  labels:
     app: pod
spec:
  nodeSelector:
    kubernetes.io/hostname: minikube-m02
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-2
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
    nodePort: 30000
  type: NodePort
  externalTrafficPolicy: Local
```
```
1. 서비스 리소스 정보를 보면 NodePort 타입, 클러스터 IP 확인 가능

2. ClusterIP 타입 처럼, ServiceIP로 접근이 가능하다.
>curl 10.107.79.156:9000/hostname
Hostname : pod-n-1

3. 2번의 예제는 2개의 파드로 잘 분산된다.

3. Node별로 InternalIP를 확인할 수 있다.
- minikube      InternalIP: 192.168.49.2
- minikube-m02  InternalIP: 192.168.49.3
- minikube-m03  InternalIP: 192.168.49.4

4. NodePort에 의해 (Node_InternalIP)로 접근이 가능하다.
curl 192.168.49.3:30000/hostname
curl 192.168.49.4:30000/hostname
curl 192.168.49.5:30000/hostname

5. 서비스의 externalTrafficPolicy 옵션때문에, 파드가 존재하는 노드에서만 접근이 가능.
curl 192.168.49.3:30000/hostname > pod-n-1
curl 192.168.49.4:30000/hostname > pod-n-2
curl 192.168.49.5:30000/hostname > ...

```

## 실습 - Service LoadBalancer

```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-3
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
  type: LoadBalancer
```

```
1. 서비스를 보면 ExternalIP가 아직 Pending 상태로 외부 아이피 할당을 기다리고 있다.

> kubectl get service
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
svc-3            LoadBalancer   10.110.41.44    <pending>     9000:30929/TCP   59s

```
# Object - Volume : emptyDir, hostPath, PV/PVC

emptyDir  

컨테이너들 끼리 데이터를 공유하기 위해 볼륨을 사용한다. 최초에는 비어 있다.   
예) 컨테이너 웹서버의 결과물을 백앤드 컨테이너가 가져가 로컬 파일처럼 사용  
Pod가 재생성이 되면 emptyDir 은 사라진다. 휘발성을 가진 내용만 넣어야 한다.  


hostPath

Pod들이 올라간 Node에서 볼륨을 만들어서 사용하는 것이다.  
Pod들이 죽어도 Node에 볼륨이 남아있는 장점이 있지만, Pod가 다른 노드에 생성될 수 있기때문에 일관성이 없다.  
Node가 추가될때마다 상위 구성의 공유 볼륨을 리눅스에서 넣어 일관성을 유지시킬 수 있긴하다.  
예) 각각의 Node에는 각 시스템 설정파일들이 있고 이를 읽을때 사용한다.
- 사전에 해당 Node에 경로가 있어야 한다. 
- Pod에서 데이터를 쓰는 용도가 아니다.


PV/PVC

PV : PersistantVolume을 / Claim
Pod에 영속성이 있는 볼륨을 제공하기 위함이다. 외부의 NFS, Storage를 연동하기 위한 솔루션이다.  
2개 영역으로 나누었다. User 영역은 Pod서비스를 배포하는 사람, Admin 영역은 K8S자체를 운영하는 관리자 이다.  

Admin : 각 볼륨들을 정의하고, PersistantVolume을 만든다.
- 어떤 서버의 어떤 경로의 스토리지를 사용하고, 권한, 총 Storage크기 등등 설정
User : PersistentVolumeClain 을 통해서 Storage를 Requests해서 사용할 수 있다. 
- Pod에는 1GB가 필요하다 > K8S가 적절한 PersistantVolume을 선택한다.

## 실습

# ConfigMap, Secret - Env, Mount

환경변수를 관리하기 위한것이 ConfigMap, Secret 이다.  
환경변수 중 상수값은 ConfigMap, 비밀키값등은 Secret에 보관한다.  Env를 각 컨테이너에 주입시키도록 한다.  

1. Env Literal , 상수로 환경변수 넣기 


2. Env File , 파일로 환경변수 넣기
key 가 file.txt Value 가 Content 이다.
kubectl 명령어로 configmap과 secret을 등록할 수 있다.
secret 은 base64 인코딩을 해서 넣는다.
한번 주입되면 변경되지 않는다.

3. Volumne mount , 볼륨으로 환경변수 넣기

볼륨이 마운트 되므로, 외부에 의해 환경 변수가 변경된다.

## 실습

# Namespace, ResourceQuota, LimitRange

Namespace : k8s클러스터에서 논리적으로 공간을 분리하여 자원 할당을 제한할 수 있다.   

ResourceQuota를 왜 써야 하는가?  
- k8s에 클러스터에는 전체 자원이 제한되어 있다.  
- 자원에는 메모리와 CPU가 대표적으로 있다.    
- cluster안에는 Namespace가 있다. 
- 한 Namespace 안의 Pod가 모든 자원을 써버리면 다른 Namespace에 문제가 발생한다.  
- ResourceQuota 로 Namespace별 자원을 할당할 수 있다.

LimitRange를 왜 써야 하는가?
- LimitRange : 한 Pod의 자원 사용량이 일정 수준 이하 라면, Namespace에 들어올 수 있다.  
- 이런 ResourceQuota, LimitRange는 Namespace뿐 아니라, Cluster단위에도 적용시킬 수 있다.  


## 1. Namespace

- 한 Namespace 안에는 중복된 이름으로 object(Pod 등)를 만들 수 없다.
- 타 Namespace과 자원이 분리된다. Service의 Selector는 동일 Namespace에서만 사용 된다.  
- 대부분의 자원들을 namespace 내에서 사용된다.
- Node,PersistantVolume 처럼 NameSpace와 상관없이 사용되는 자원도 있다.  
- Namespace를 지우게 되면, 그 안의 자원(Pod)도 사라지게 된다.
- 서로 다른 Namespace의 Pod는 연결이 기본적으로 된다. 추후 Network 설정으로 대응 가능


## 2. ResourceQuota

- Namespace의 전체 자원을 명시 해준다.  
- 3Gi~8Gi 메모리를 사용하고 싶다면 각각 requests, limits 필드에 정의한다.
- ResourceQuota가 지정된 Namespace에 Pod를 만들려면, 리소스 스펙을 지정해줘야 한다.  
- 제한 대상 : Compute Resource (CPU, Memory, Storage), Object Count (Pod, Service, ConfigMap, PVC..)  
- k8s 버전마다 제한할 수 있는 오브젝트가 다르다.  

## 3. LimitRange  

각각의 Pod마다 Namespace에 들어올 수 있는지 체크를 해준다.  

```
    min: # 메모리 하한값
      memory: 0.1Gi
    max: # 메모리 상한값
      memory: 0.5Gi
    maxLimitRequestRatio: # Pod의 상한/하한 <= 3 이어야 한다. 
      memory: 3
    defaultRequest: # Pod의 자원 할당 디폴트값
      memory: 0.1Gi
    default: # Pod의 자원 할당 디폴트값
      memory: 0.5Gi
```
## 실습 Namespace

## 실습 - Namespace에 같은 이름의 pod 생성 불가

네임스페이스 생성  

```
apiVersion: v1
kind: Namespace
metadata:
  name: nm-1
```

nm-1 Namespace에 pod 생성
```
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  namespace: nm-1
  labels:
    app: pod
spec:
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
```
- 대시보드에서 nm-1 namespace를 선택후 만들어야 한다.
- 동일한 이름 pod생성 불가 -  pods "pod-1" already exists

nm-1 Namespace에 Service 생성
```
apiVersion: v1
kind: Service
metadata:
  name: svc-1
  namespace: nm-1
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080

```


## 실습 - 다른 네임스페이스의 pod가 연결되는것을 확인

## 실습 - 노드포트는 namespace내 중복되면 안된다.

## 실습 - host-path의 volumne 마운트는 namespace간 연동된다.

---
## 실습 ResourceQuota

## 실습 - ResourceQuota 자원을 넘어선 파드 생성 불가

## 실습 - ResourceQuota 파드수 제한

## 실습 - 파드를 먼저 생성 후 ResourceQuota를 만들 경우
- ResourceQuota가 잘 만들어진다.
- 그래서 namespace가 빈 상태에서 ResourceQuota를 만들어야 한다.

---
## 실습 LimitRange

## 실습 LimitRange 설정 후 Pod의 limit 걸리는 경우, ratio 걸리는 경우

## 실습 LimitRange의 기본설정을 따라가는 Pod 리소스 확인

## 실습 LimitRange를 여러개 설정은 권장하지 않음